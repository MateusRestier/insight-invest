1. Problema: Rotulagem Inicial Simplista e Redundância do Modelo
A Preocupação: A primeira versão do classificador.py usava regras fixas e arbitrárias para criar os rótulos "Recomendado/Não Recomendado" (ex: P/L < 10 e ROE > 15%).
 Você corretamente identificou que treinar um modelo de Machine Learning com esses rótulos era redundante; o modelo simplesmente aprenderia a replicar o filtro que já havíamos criado, sem gerar novos insights.
A Solução Implementada:
Abandonamos a rotulagem baseada em filtros.
Implementamos no classificador.py uma estratégia de rotulagem baseada em desempenho futuro relativo.
 Definimos um "bom resultado" (rótulo 1) como uma ação cujo preço estivesse no Top 25% de desempenho nos 10 dias seguintes,
  e um "mau resultado" (rótulo 0) como uma ação no Bottom 25%. Isso forçou o modelo a aprender padrões preditivos reais nos dados, em vez de apenas replicar regras.

2. Problema: Dependência Excessiva da variacao_12m e o Risco de "Comprar no Topo"
A Preocupação: Após o primeiro treinamento com a nova rotulagem, você observou que a feature variacao_12m (momentum) se tornou a mais importante.
 Você levantou a preocupação muito pertinente de que isso poderia levar o modelo a recomendar ações que já subiram muito
 (risco de "comprar no topo") ou ações fundamentalmente fracas que tiveram uma recuperação de preço volátil (como AMER3 ou PETZ3).
A Solução Implementada:
Tentativa 1: Retreinamos o modelo no classificador.py removendo completamente a variacao_12m.
 Isso provou que o modelo ainda tinha alta performance, mas você preferiu manter a informação de momentum se pudéssemos controlar sua influência.
Tentativa 2 (Sucedida): Ajustamos o hiperparâmetro max_features do RandomForestClassifier para 0.5.
 Isso forçou o modelo a considerar um subconjunto aleatório maior de features em cada divisão,
 "obrigando-o" a distribuir a importância de forma mais equilibrada e a não depender excessivamente de um único indicador.

3. Problema: Modelo Recomendando Ações Fundamentalmente Fracas (Caso PETZ3)
A Preocupação: Mesmo com os ajustes, o modelo ainda recomendava fortemente ações como a PETZ3,
 que apresentava P/L e ROE negativos. Você concluiu que o modelo estava otimizando para "repique de preços" de curto prazo,
 ignorando a qualidade fundamental da empresa.
A Solução Implementada:
Refinamos a lógica de rotulagem no classificador.py mais uma vez. Em vez de apenas filtrar os dados,
mudamos a definição de um "bom resultado" (rótulo 1). Uma ação agora só recebe o rótulo 1 se ela:
Tiver um ótimo desempenho de preço (Top 25%);
E atender a critérios mínimos de qualidade (P/L > 0 e ROE > 0).
Isso ensinou o modelo a ignorar "saltos" de preço em empresas com prejuízo,
tornando-o muito mais alinhado a uma filosofia de investimento de qualidade.

4. Problema: Justificativas Heurísticas Enganosas (Caso AMER3)
A Preocupação: O modelo, treinado com a lógica de qualidade, corretamente não recomendou a AMER3.
No entanto, a função gerar_justificativas no recomendador_acoes.py interpretava os indicadores
distorcidos da AMER3 (P/L extremamente baixo, ROE irrealisticamente alto) como "pontos positivos", o que era enganoso.
A Solução Implementada:
Adicionamos "filtros de sanidade" às regras dentro da função gerar_justificativas.
Definimos faixas razoáveis para os indicadores. Agora, um P/L entre 0 e 2 ou um ROE acima de 50% são corretamente classificados como "pontos negativos/de atenção",
pois indicam risco ou distorção contábil, tornando as justificativas muito mais inteligentes e alinhadas com a realidade.

5. Problema: Risco de Imputação de Dados e Vício por Coletas Diárias

A Preocupação:
Imputação de Dados: no início, optamos por usar o SimpleImputer para preencher com a mediana as lacunas de informação de algumas ações no Investidor10 (já que nem todas traziam todos os indicadores).
Contudo, percebemos que esse preenchimento poderia mascarar cenários reais — por exemplo, uma empresa sem Dividend Yield reportado acabaria “recebendo” um valor mediano e passando como se tivesse histórico concreto.
Coleta Diária Viciada: além disso, o scraper roda todo dia para inserir no banco múltiplas observações da mesma ação com variações ínfimas.
Com isso, os quartis que separam os 25 % melhores e 25 % piores passaram a se “encher” de linhas quase idênticas,
reduzindo drasticamente a diversidade de exemplos e prejudicando a capacidade do modelo de aprender padrões genuínos de valorização ou queda.
A Solução Implementada:
Descartamos o Imputer e removemos colunas instáveis: em vez de mascarar valores faltantes, eliminamos as features que apresentavam muitos missing e mantivemos apenas aquelas com cobertura consistente, garantindo que o modelo trabalhe só com dados reais.
Eliminação de duplicatas exatas: antes de qualquer divisão de treino/teste, removemos linhas perfeitamente idênticas para impedir que coletas repetidas viciem os quartis de classificação.
Hold-out temporal verdadeiro (últimos 20 %): separamos os 20 % mais recentes dos dados para avaliação final, simulando um cenário real de previsão sem jamais “espionar” o futuro.
Validação Cruzada Temporal (TimeSeriesSplit): substituímos o train_test_split aleatório por k-fold temporal, garantindo que cada fold de teste contenha apenas observações posteriores às de treino.
RandomizedSearchCV com folds temporais: todo o tuning de hiperparâmetros foi feito exclusivamente sobre o conjunto de treino temporal, preservando o hold-out para avaliação out-of-sample.
Com isso, eliminamos o vazamento temporal, mantivemos o modelo focado em padrões robustos e asseguramos que nem a coleta diária nem a imputação artificial prejudiquem a qualidade ou a transparência da análise.

6. Problema: Quero uma regressão para prever o preço futuro das ações e comparar com o valor real.
A Preocupação:
Ter uma previsão quantitativa de preços futuros pode ajudar a avaliar o potencial de valorização das ações ao longo de um curto prazo (exemplo: 10 dias).
No entanto, é importante evitar previsões ilusórias ou muito desconectadas da realidade,
por isso a ideia é sempre comparar a previsão com o valor que realmente aconteceu no mercado.
Além disso, era necessário garantir que o modelo fosse treinado de forma temporalmente coerente, sem "vazamento de dados futuros".

A Solução Implementada:
Foi desenvolvido um pipeline de regressão usando o algoritmo RandomForestRegressor. O modelo utiliza como entrada os indicadores fundamentalistas das ações
(ex: PL, PVP, ROE, entre outros). O target é o preço da ação em um horizonte futuro de N dias, calculado a partir da base histórica armazenada no banco de dados.
O processo de treino respeitou uma divisão hold-out temporal, separando os últimos N dias para teste, simulando o cenário real de uma previsão futura. Após o treinamento,
o modelo gera previsões para o período de teste e os resultados (preço real, preço previsto e erro percentual) são armazenados na tabela resultados_precos.
Isso permite validar a assertividade da regressão ao longo do tempo e alimentar análises comparativas entre valor previsto e valor real de mercado.

7. Problema: Processamento Lento na Previsão de Múltiplo(problema 7)s Dias
A Preocupação:
A implementação original para prever o preço de uma ação para vários dias no futuro era muito lenta, impactando negativamente a experiência do usuário no dashboard.
Ao solicitar uma previsão para N dias, o sistema executava um loop que, para cada dia, realizava o ciclo completo de:
Conectar-se ao banco de dados.
Carregar todo o histórico de indicadores financeiros.
Processar e preparar todos esses dados.
Treinar um modelo de regressão.
Essa repetição de tarefas pesadas e redundantes, especialmente o carregamento dos mesmos dados do banco de dados N vezes, criava um grande gargalo de performance,
tornando o tempo de espera proibitivo para um horizonte de previsão maior.

A Solução Implementada:
A solução foi refatorar e otimizar o pipeline de regressão para eliminar a redundância. Foi criada uma nova função centralizada, a executar_pipeline_multidia, com a seguinte lógica:
Otimização de Dados: A função agora carrega os dados do banco de dados e executa o pré-processamento inicial (cálculo de features) uma única vez, antes de iniciar qualquer cálculo de previsão.
Loop Eficiente: Com os dados já em memória, a função entra em um loop que itera pelo número de dias a prever.
Em cada iteração, ela apenas realiza as tarefas específicas daquele horizonte: cria a variável alvo (preco_futuro_N_dias), treina o modelo e gera a previsão, reutilizando os dados já processados.
Integração com o Dashboard: O código do dashboard (previsoes.py) foi modificado para chamar essa nova função otimizada uma única vez,
passando a ela a responsabilidade de calcular todas as previsões de uma só vez.

Essa mudança transformou um processo de N operações pesadas em uma única operação pesada seguida por N operações leves, resultando em uma melhoria drástica de performance e na redução significativa do tempo de espera para o usuário.